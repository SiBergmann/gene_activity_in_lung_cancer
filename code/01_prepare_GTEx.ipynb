{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data from GTEx\n",
    "Link: https://www.gtexportal.org/home/downloads/adult-gtex/bulk_tissue_expression\n",
    "\n",
    "\n",
    "**Bulk-Tissue-Expression:**\n",
    "\n",
    "Contains the gene expression in *healthy* tissue samples from adults. For each gene, the transcription value for each tissue is listed.\n",
    "\n",
    "**Output file format:**\n",
    "* Ensemble ID\n",
    "* TPM value"
   ],
   "id": "c61097af660cd39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Data and melt down to long format\n",
    "â†’ takes 20 minutes with 3000 rows per chunk\n",
    "\n",
    "The format of the input file is a column per tissue.\n",
    "We load the data in chunks and melt it down to a long format with columns for the gene name, tissue and TPM value.\n"
   ],
   "id": "888769a39c83248e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:25:21.738988Z",
     "start_time": "2025-01-02T14:25:19.181449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "import gzip\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import urllib.request"
   ],
   "id": "518bd896c871130",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:25:21.757799Z",
     "start_time": "2025-01-02T14:25:21.753005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to analyze the dataset\n",
    "def dataset_analysis(df):\n",
    "    global missing_values, min_tpm, max_tpm\n",
    "    \n",
    "    missing_values =+ df.isnull().sum()\n",
    "     \n",
    "    if df['tpm'].min() < min_tpm:\n",
    "        min_tpm = df['tpm'].min()\n",
    "        \n",
    "    if df['tpm'].max() > max_tpm:\n",
    "        max_tpm = df['tpm'].max()"
   ],
   "id": "1af4b9f2c4443152",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:25:21.768997Z",
     "start_time": "2025-01-02T14:25:21.762806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# download the data\n",
    "url = \"https://storage.googleapis.com/adult-gtex/bulk-gex/v8/rna-seq/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct.gz\"\n",
    "\n",
    "zip_file_name = \"../import_data/GTEx/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct.gz\"\n",
    "\n",
    "file_name = \"../import_data/GTEx/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct\"\n",
    "\n",
    "os.makedirs(\"../import_data\", exist_ok=True)\n",
    "os.makedirs(\"../import_data/GTEx\", exist_ok=True)\n",
    "\n",
    "\n",
    "if not os.path.exists(zip_file_name):\n",
    "    urllib.request.urlretrieve(url, zip_file_name)\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    with gzip.open(zip_file_name, 'rb') as f_in:\n",
    "        with open(file_name, 'wb') as f_out:\n",
    "            f_out.write(f_in.read())"
   ],
   "id": "8dca31e366eef810",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:47:14.048962Z",
     "start_time": "2025-01-02T14:25:21.776001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = \"../processed_data/GTEX_healthy.csv\"\n",
    "\n",
    "os.makedirs(\"../processed_data\", exist_ok=True)\n",
    "\n",
    "# Initialize an output file and overwrite if already exists\n",
    "with open(output_file, 'w') as f_out:\n",
    "    f_out.write(\"id,tissue,tpm\\n\")\n",
    "\n",
    "missing_values = 0\n",
    "min_tpm = float('+inf')\n",
    "max_tpm = float('-inf')\n",
    "\n",
    "chunksize = 2000\n",
    "save_threshold = 10000\n",
    "\n",
    "output_chunks = []\n",
    "outputrows = 0\n",
    "\n",
    "with pd.read_csv(file_name, delimiter=\"\\t\", skiprows=2, chunksize=chunksize) as reader:\n",
    "    counter = 0\n",
    "\n",
    "    for df_chunk in reader:\n",
    "        start_time = time.time()\n",
    "        df_list = []\n",
    "        \n",
    "        # cleanup\n",
    "        df_chunk = df_chunk.drop(columns=['Description'])\n",
    "        df_chunk.rename(columns={'Name':'id'}, inplace=True)\n",
    "        df_chunk['id'] = df_chunk['id'].str.split('.').str[0]\n",
    "        \n",
    "        df_long = pd.melt(df_chunk, id_vars=['id'], var_name='tissue', value_name='tpm', ignore_index=True)\n",
    "\n",
    "\n",
    "        df_long[\"tpm\"] = df_long[\"tpm\"].astype(float)\n",
    "        \n",
    "        output_chunks.append(df_long)\n",
    "        outputrows += df_long.shape[0]\n",
    "        \n",
    "        dataset_analysis(df_long)\n",
    "        \n",
    "        if outputrows >= save_threshold:\n",
    "            pd.concat(output_chunks).to_csv(output_file, mode='a', header=False, index=False)\n",
    "            output_chunks.clear()\n",
    "        \n",
    "        # Clear memory\n",
    "        del df_long\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time        \n",
    "        print(f\"{counter} / 56200 processed in {duration:.2f} seconds\")\n",
    "        \n",
    "        counter += chunksize\n",
    "        \n",
    "if output_chunks:\n",
    "    pd.concat(output_chunks).to_csv(output_file, mode='a', header=False, index=False)\n",
    "        \n",
    "print(f\"Output file contains {outputrows} rows\")"
   ],
   "id": "a56f88bb71eb16f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 56200 processed in 41.44 seconds\n",
      "2000 / 56200 processed in 40.22 seconds\n",
      "4000 / 56200 processed in 39.29 seconds\n",
      "6000 / 56200 processed in 39.61 seconds\n",
      "8000 / 56200 processed in 39.93 seconds\n",
      "10000 / 56200 processed in 38.39 seconds\n",
      "12000 / 56200 processed in 39.33 seconds\n",
      "14000 / 56200 processed in 39.12 seconds\n",
      "16000 / 56200 processed in 40.07 seconds\n",
      "18000 / 56200 processed in 40.01 seconds\n",
      "20000 / 56200 processed in 37.84 seconds\n",
      "22000 / 56200 processed in 38.75 seconds\n",
      "24000 / 56200 processed in 39.39 seconds\n",
      "26000 / 56200 processed in 40.32 seconds\n",
      "28000 / 56200 processed in 41.97 seconds\n",
      "30000 / 56200 processed in 40.95 seconds\n",
      "32000 / 56200 processed in 39.38 seconds\n",
      "34000 / 56200 processed in 38.04 seconds\n",
      "36000 / 56200 processed in 40.00 seconds\n",
      "38000 / 56200 processed in 39.29 seconds\n",
      "40000 / 56200 processed in 40.44 seconds\n",
      "42000 / 56200 processed in 40.29 seconds\n",
      "44000 / 56200 processed in 39.50 seconds\n",
      "46000 / 56200 processed in 40.63 seconds\n",
      "48000 / 56200 processed in 41.61 seconds\n",
      "50000 / 56200 processed in 38.34 seconds\n",
      "52000 / 56200 processed in 39.56 seconds\n",
      "54000 / 56200 processed in 40.26 seconds\n",
      "56000 / 56200 processed in 4.33 seconds\n",
      "Output file contains 976868400 rows\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze the dataset",
   "id": "b0a9862eeef3957e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:47:14.362007Z",
     "start_time": "2025-01-02T14:47:14.357006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Missing values:\\n\"\n",
    "      f\"{missing_values}\\n\")\n",
    "print(f\"Min TPM: {min_tpm}\")\n",
    "print(f\"Max TPM: {max_tpm}\")"
   ],
   "id": "f69b10e5a76aeea1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "id        0\n",
      "tissue    0\n",
      "tpm       0\n",
      "dtype: int64\n",
      "\n",
      "Min TPM: 0.0\n",
      "Max TPM: 747400.0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save grouped data",
   "id": "3fd646174a512c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:53:14.349168Z",
     "start_time": "2025-01-02T14:47:14.373732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file = \"../processed_data/GTEX_healthy.csv\"\n",
    "output_file = \"../processed_data/GTEX_healthy_temp.csv\"\n",
    "\n",
    "#chunksize = 200000000\n",
    "chunksize = 20000000\n",
    "\n",
    "# Initialize output file and overwrite if already exists\n",
    "with open(output_file, 'w') as f_out:\n",
    "    f_out.write(\"id,tmp sum,tmp count\\n\")\n",
    "    \n",
    "with (pd.read_csv(file, chunksize=chunksize) as reader):\n",
    "    for df_chunk in reader:\n",
    "        start_time = time.time()\n",
    "        df_mean = df_chunk.drop(columns=[\"tissue\"])\n",
    "        df_mean = df_mean.groupby('id').agg(['sum','count'])\n",
    "        df_mean.to_csv(output_file, mode='a', header=False, index=True)\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"{df_mean.shape[0]} rows processed in {duration:.2f} seconds\")\n",
    "\n",
    "        del df_mean\n",
    "        gc.collect()"
   ],
   "id": "78ba3d08379b4dfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 rows processed in 1.35 seconds\n",
      "4000 rows processed in 1.37 seconds\n",
      "2000 rows processed in 1.22 seconds\n",
      "4000 rows processed in 1.18 seconds\n",
      "2000 rows processed in 1.21 seconds\n",
      "4000 rows processed in 1.22 seconds\n",
      "4000 rows processed in 1.17 seconds\n",
      "2000 rows processed in 1.18 seconds\n",
      "4000 rows processed in 1.14 seconds\n",
      "2000 rows processed in 1.26 seconds\n",
      "4000 rows processed in 1.14 seconds\n",
      "2000 rows processed in 1.10 seconds\n",
      "4000 rows processed in 1.36 seconds\n",
      "4000 rows processed in 1.23 seconds\n",
      "2000 rows processed in 1.13 seconds\n",
      "4000 rows processed in 1.22 seconds\n",
      "2000 rows processed in 1.13 seconds\n",
      "4000 rows processed in 1.17 seconds\n",
      "2000 rows processed in 1.16 seconds\n",
      "4000 rows processed in 1.18 seconds\n",
      "4000 rows processed in 1.18 seconds\n",
      "2000 rows processed in 1.11 seconds\n",
      "4000 rows processed in 1.20 seconds\n",
      "2000 rows processed in 1.16 seconds\n",
      "4000 rows processed in 1.27 seconds\n",
      "2000 rows processed in 1.14 seconds\n",
      "4000 rows processed in 1.18 seconds\n",
      "4000 rows processed in 1.28 seconds\n",
      "2000 rows processed in 1.20 seconds\n",
      "4000 rows processed in 1.23 seconds\n",
      "2000 rows processed in 1.17 seconds\n",
      "4000 rows processed in 1.29 seconds\n",
      "2000 rows processed in 1.22 seconds\n",
      "4000 rows processed in 1.36 seconds\n",
      "4000 rows processed in 1.17 seconds\n",
      "2000 rows processed in 1.50 seconds\n",
      "4000 rows processed in 1.34 seconds\n",
      "2000 rows processed in 1.27 seconds\n",
      "4000 rows processed in 1.17 seconds\n",
      "4000 rows processed in 1.36 seconds\n",
      "2000 rows processed in 1.19 seconds\n",
      "4000 rows processed in 1.32 seconds\n",
      "2000 rows processed in 1.20 seconds\n",
      "4000 rows processed in 1.22 seconds\n",
      "2000 rows processed in 1.15 seconds\n",
      "4000 rows processed in 1.18 seconds\n",
      "3966 rows processed in 1.15 seconds\n",
      "2000 rows processed in 1.16 seconds\n",
      "2190 rows processed in 0.96 seconds\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load temp file to calculate mean TPM",
   "id": "5f81dfabf6b26900"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:53:14.508136Z",
     "start_time": "2025-01-02T14:53:14.384653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_mean = pd.read_csv(\"../processed_data/GTEX_healthy_temp.csv\")\n",
    "df_mean = df_mean.groupby('id').sum()\n",
    "df_mean['tpm'] = df_mean['tmp sum']/df_mean['tmp count']\n",
    "df_mean"
   ],
   "id": "32643736f566c7ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       tmp sum  tmp count        tpm\n",
       "id                                                  \n",
       "ENSG00000000003  274030.408120      17382  15.765183\n",
       "ENSG00000000005   62036.191561      17382   3.568990\n",
       "ENSG00000000419  841623.549500      17382  48.419258\n",
       "ENSG00000000457  101256.444200      17382   5.825362\n",
       "ENSG00000000460   41291.764070      17382   2.375547\n",
       "...                        ...        ...        ...\n",
       "ENSG00000284592      27.276690      17382   0.001569\n",
       "ENSG00000284594      88.438900      17382   0.005088\n",
       "ENSG00000284595    7720.422600      17382   0.444162\n",
       "ENSG00000284596     158.655000      17382   0.009128\n",
       "ENSG00000284600    5818.659996      17382   0.334752\n",
       "\n",
       "[56156 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp sum</th>\n",
       "      <th>tmp count</th>\n",
       "      <th>tpm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <td>274030.408120</td>\n",
       "      <td>17382</td>\n",
       "      <td>15.765183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <td>62036.191561</td>\n",
       "      <td>17382</td>\n",
       "      <td>3.568990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <td>841623.549500</td>\n",
       "      <td>17382</td>\n",
       "      <td>48.419258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <td>101256.444200</td>\n",
       "      <td>17382</td>\n",
       "      <td>5.825362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <td>41291.764070</td>\n",
       "      <td>17382</td>\n",
       "      <td>2.375547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000284592</th>\n",
       "      <td>27.276690</td>\n",
       "      <td>17382</td>\n",
       "      <td>0.001569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000284594</th>\n",
       "      <td>88.438900</td>\n",
       "      <td>17382</td>\n",
       "      <td>0.005088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000284595</th>\n",
       "      <td>7720.422600</td>\n",
       "      <td>17382</td>\n",
       "      <td>0.444162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000284596</th>\n",
       "      <td>158.655000</td>\n",
       "      <td>17382</td>\n",
       "      <td>0.009128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000284600</th>\n",
       "      <td>5818.659996</td>\n",
       "      <td>17382</td>\n",
       "      <td>0.334752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56156 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean up",
   "id": "84729111802caf77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:53:14.552644Z",
     "start_time": "2025-01-02T14:53:14.543909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_mean = df_mean.drop(columns=['tmp sum', 'tmp count'])\n",
    "\n",
    "df_mean.reset_index(inplace=True)\n",
    "\n",
    "df_mean.rename(columns={'tpm':'healthy TPM',\n",
    "                        'id': 'Gene ID'}, inplace=True)\n",
    "\n",
    "# reorder columns\n",
    "df_mean = df_mean[['Gene ID', 'healthy TPM']]"
   ],
   "id": "97d24d291058c269",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:53:14.563711Z",
     "start_time": "2025-01-02T14:53:14.558204Z"
    }
   },
   "cell_type": "code",
   "source": "df_mean",
   "id": "ef3aae2170d931d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               Gene ID  healthy TPM\n",
       "0      ENSG00000000003    15.765183\n",
       "1      ENSG00000000005     3.568990\n",
       "2      ENSG00000000419    48.419258\n",
       "3      ENSG00000000457     5.825362\n",
       "4      ENSG00000000460     2.375547\n",
       "...                ...          ...\n",
       "56151  ENSG00000284592     0.001569\n",
       "56152  ENSG00000284594     0.005088\n",
       "56153  ENSG00000284595     0.444162\n",
       "56154  ENSG00000284596     0.009128\n",
       "56155  ENSG00000284600     0.334752\n",
       "\n",
       "[56156 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene ID</th>\n",
       "      <th>healthy TPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>15.765183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>3.568990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>48.419258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>5.825362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>2.375547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56151</th>\n",
       "      <td>ENSG00000284592</td>\n",
       "      <td>0.001569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56152</th>\n",
       "      <td>ENSG00000284594</td>\n",
       "      <td>0.005088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56153</th>\n",
       "      <td>ENSG00000284595</td>\n",
       "      <td>0.444162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56154</th>\n",
       "      <td>ENSG00000284596</td>\n",
       "      <td>0.009128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56155</th>\n",
       "      <td>ENSG00000284600</td>\n",
       "      <td>0.334752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56156 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save final file",
   "id": "37c954afab5aab4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:53:14.672173Z",
     "start_time": "2025-01-02T14:53:14.597349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_mean.to_csv(\"../processed_data/GTEX_healthy_mean.csv\")\n",
    "print(f'There are {df_mean.shape[0]} genes in the final file')"
   ],
   "id": "848869f23fb845ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 56156 genes in the final file\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:53:15.399277Z",
     "start_time": "2025-01-02T14:53:14.827152Z"
    }
   },
   "cell_type": "code",
   "source": "dfi.export(df_mean.head(5), \"../tex/figures/03_01_GTEX_healthy_mean.png\")",
   "id": "f44ded1a523df2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate html\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
